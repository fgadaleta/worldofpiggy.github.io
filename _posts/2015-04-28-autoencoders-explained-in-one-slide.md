---
layout: post
title: Autoencoders explained in one slide
comments: true
tags: [artificial intelligence, autoencoders, big data, deep learning, dimensionality, neural networks, pca, reduction, AI]
---

Autoencoders represent an amazing trick to learn the structure within the
input data. In a neural network, learning the weights of the hidden layer to
represent the input is an approach that tries to discover the geometry of the
data, if any. When the hidden units are fewer than the dimensions of the input
data, autoencoders resemble Principal Component Analysis PCA. 
The main difference between the two is that the non-linear function of autoencoders can
capture the non-linearity within the data (if any). Something that is not possible to achieve with PCA. 

![Autoencoders](https://s3-eu-west-1.amazonaws.com/wopcontent/uploads/2015/04/autoencoders.png?w=640) 

